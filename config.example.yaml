# =============================================================================
# PR Review Automation Configuration (Example)
# =============================================================================

log:
  level: INFO                   # Log level (DEBUG, INFO, WARN, ERROR)
  format: text                  # Log format (text, json)
  output: stdout,logs/app.log   # Log output (stdout, stderr, file path)
  rotation:
    max_size: 100               # Max size of a single log file (MB)
    max_backups: 10             # Max number of old log files to retain
    max_age: 7                  # Max number of days to retain old log files
    compress: true              # Whether to compress old log files

server:
  port: 8080                    # Server listening port
  concurrency_limit: 10         # Concurrency limit for requests
  read_timeout: 10s             # Timeout for reading request body
  write_timeout: 30s            # Timeout for writing response
  shutdown_timeout: 30s         # Timeout for graceful shutdown
  max_body_size: 2097152        # Max request body size (bytes, default 2MB)

llm:
  model: qwen3-coder            # LLM model name
  endpoint: http://localhost:8081/v1 # LLM API endpoint (OpenAI compatible)
  timeout: 120s                 # LLM request timeout
  max_concurrency: 1            # Max concurrent LLM requests

mcp:
  retry:
    attempts: 3                 # MCP call retry attempts
    backoff: 1s                 # Initial retry backoff duration
    max_backoff: 30s            # Max retry backoff duration
  
  timeout: 30s                  # MCP tool call timeout
  circuit_breaker:              # Circuit breaker configuration
    failure_threshold: 3        # Number of consecutive failures to trigger circuit breaker
    open_duration: 30s          # Duration to keep circuit open

  bitbucket:
    endpoint: http://localhost:8082 # Bitbucket MCP server endpoint
    web_url: "https://bitbucket.example.com" # Required for clickable links in comments
    auth_header: Bitbucket-Token    # Authorization header name
    allowed_tools:                  # Whitelist of allowed tools
      - capabilities
      - bitbucket_get_pull_request
      - bitbucket_get_pull_request_diff
      - bitbucket_get_pull_request_changes
      - bitbucket_get_pull_request_comments
      - bitbucket_get_file_content
      - bitbucket_add_pull_request_comment
      - bitbucket_get_commits
      - bitbucket_get_diff_between_commits
      - bitbucket_get_commit
    
    response_filters:           # Response filter configuration
      - name: "truncate"        # Filter name: truncate
        options:
          max_len: 100000       # Max length limit

  jira:
    endpoint: ""                # Jira MCP server endpoint (leave empty to disable)
    auth_header: Jira-Token     # Authorization header name
    allowed_tools: []           # Whitelist of allowed tools

  confluence:
    endpoint: ""                # Confluence MCP server endpoint (leave empty to disable)
    auth_header: Confluence-Token # Authorization header name
    allowed_tools: []           # Whitelist of allowed tools

webhook:
  max_retries: 3                # Max retries for webhook processing failures

prompts:
  dir: prompts                  # Directory for prompt template files

pipeline:
  enabled: true                 # Enable pipeline mode (Stage 1-3)
  backend: direct               # Backend mode: direct (LLM direct) or agent (Agentic)
  max_concurrent_comments: 5    # Max concurrent comments to submit
  response_max_string_len: 100000 # Max string length for response

  stage2_context:               # Stage 2: Context enrichment config
    max_extra_files: 5          # Max extra files to include
    max_file_size: 50000        # Max file size to read (bytes)

  stage3_review:                # Stage 3: Code review config
    temperature: 0.0            # LLM temperature
    max_context_tokens: 256000  # Max context token limit
    degradation:                # Degradation strategy (when context limit exceeded)
      l1_context_lines: 50      # L1: Context lines to keep around changes
      l2_chunk_by_file: true    # L2: Chunk processing by file
      l3_diff_only: true        # L3: Fallback to diff only (skip reading full file)

  comment_merge:                # Comment merge strategy
    enabled: true               # Enable comment merging
    high_severity_merge: "none" # Merge strategy for high severity: "by_file" (per file), "none" (inline)
    low_severity_merge: "to_summary" # Merge strategy for low severity: "to_summary", "none"
    include_low_in_summary: true # Include low severity issues in summary

storage:
  driver: sqlite                # Storage driver (sqlite supported)
  dsn: "data/reviews.db"        # Database connection string / file path
  timeout: 5s                   # Storage operation timeout
